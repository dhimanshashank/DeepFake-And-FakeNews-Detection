# -*- coding: utf-8 -*-
"""deepfake_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ee8Ad_QR6vvLR6_Um51hwniqDmbr-2S

# **Data Preprocessing for Images**

## Neccessary Checks
"""

from google.colab import drive
drive.mount('/content/drive')

"""Used to check out which gpu is being used : such as Tesla T4"""

!nvidia-smi

"""Checking if the tensorflow is working properly and also checking out the current version of the tensorflow."""

import tensorflow as tf
tf.__version__

"""What is done here:
* Building various directories for train, test and validate.
* Splitting the complete dataset on the splitting criteria of
70:15:15 (train | test | validate).
* Moving the shuffled dataset into respective directories for respective use cases.

# **Data preparation**

## Splitting the Dataset and Saving the images to their respective directories
"""

import os
import shutil
import random
import os
import shutil
import random

# Define directories
dataset_dir = '/content/drive/MyDrive/Dataset'
validation_real_dir = '/content/drive/MyDrive/Dataset/Validation/Real'
validation_fake_dir = '/content/drive/MyDrive/Dataset/Validation/Fake'
test_real_dir = '/content/drive/MyDrive/Dataset/Test/Real'
test_fake_dir = '/content/drive/MyDrive/Dataset/Test/Fake'
train_dir = '/content/drive/MyDrive/Dataset/Train'

# Create Train directory if it doesn't exist
if not os.path.exists(train_dir):
    os.makedirs(train_dir)

# Function to copy a subset of files from source to destination
def copy_subset(source_dir, destination_dir, subset_percentage):
    if not os.path.exists(destination_dir):
        os.makedirs(destination_dir)
    files = os.listdir(source_dir)
    random.shuffle(files)  # Shuffle files
    num_files_subset = int(subset_percentage * len(files))
    subset_files = files[:num_files_subset]
    for file in subset_files:
        src = os.path.join(source_dir, file)
        dst = os.path.join(destination_dir, file)
        try:
            shutil.copy(src, dst)
        except FileNotFoundError:
            print(f"File {file} not found, continuing...")
            continue

# Define subset percentage
subset_percentage = 0.7

# Copy a subset of files from Validation directories to Train/Real and Train/Fake directories
copy_subset(validation_real_dir, os.path.join(train_dir, 'Real'), subset_percentage)
copy_subset(validation_fake_dir, os.path.join(train_dir, 'Fake'), subset_percentage)

# Copy a subset of files from Test directories to Train/Real and Train/Fake directories
copy_subset(test_real_dir, os.path.join(train_dir, 'Real'), subset_percentage)
copy_subset(test_fake_dir, os.path.join(train_dir, 'Fake'), subset_percentage)


# Preprocessing complete
print("Data preprocessing completed.")

"""## **Calculatting the number of images in each directories**"""

import os

# Define the paths to the train, test, and validate directories
train_dir = "/content/drive/MyDrive/Dataset/Train"
test_dir = "/content/drive/MyDrive/Dataset/Test"
val_dir = "/content/drive/MyDrive/Dataset/Validation"

# Function to count the number of images in a directory
def count_images(directory):
    count = sum(len(files) for _, _, files in os.walk(directory))
    return count

# Count the number of images in each directory
train_images = count_images(train_dir)
test_images = count_images(test_dir)
val_images = count_images(val_dir)

# Print the results
print("Number of images in train directory:", train_images)
print("Number of images in test directory:", test_images)
print("Number of images in validate directory:", val_images)

