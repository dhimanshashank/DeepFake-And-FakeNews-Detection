# -*- coding: utf-8 -*-
"""deepfake_vgg16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fdYavcDSaNKiKrf52lp_yl7Mm0wqy-pq

# DeepFake Detection Model - VGG16

Importing libraries in oder build the model
"""

import numpy as np
import matplotlib.pyplot as plt
import itertools
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator   # real time data augmentation
from tensorflow.keras.applications import VGG16                       # loading pre-trained model
from tensorflow.keras.layers import Dense, Flatten                    #adding fully connected layers
from tensorflow.keras.models import Model

"""Defining the image dimensions in the acceptable for the VGG16 model and also defining the batch size"""

# Define image dimensions
img_height, img_width = 224, 224
batch_size = 32

"""Function in order to define the subset of the dataset as the entire dataset is very large and then loading the datasets for Training.."""

# Function to load a subset of data from the dataset
def load_data_subset(directory, subset_percentage, target_size=(img_height, img_width)):
    datagen = ImageDataGenerator(rescale=1./255, validation_split=1.0 - subset_percentage)
    generator = datagen.flow_from_directory(
        directory,
        target_size=target_size,
        batch_size=batch_size,
        class_mode='binary',
        shuffle=True,
        subset='training'
    )
    return generator

# Define subset percentage
subset_percentage = 0.3  # Change this to desired percentage

# Load subset of training and validation data
train_generator = load_data_subset('/content/drive/MyDrive/Dataset/Train', subset_percentage)
val_generator = load_data_subset('/content/drive/MyDrive/Dataset/Validation', subset_percentage)

"""Load pre-trained VGG16 model and giving the input shape and keeping the trained model same"""

# Load pre-trained VGG16 model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))

# Freeze the convolutional base
base_model.trainable = False

# Add custom classification layers
x = Flatten()(base_model.output)
x = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create the model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""Actual training occurs here..."""

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=5,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

# Evaluate the model
loss, accuracy = model.evaluate(val_generator)
print("Validation Accuracy:", accuracy)

# Fine-tune the model
base_model.trainable = True
fine_tune_at = 200  # Fine-tune from this layer onwards
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
history_fine_tune = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=10,  # Adjust epochs as needed
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

# Generate predictions
val_generator.reset()
y_pred = model.predict(val_generator)
y_pred = np.round(y_pred).reshape(-1)

# Get true labels
y_true = val_generator.classes

# Generate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(2)  # Assuming only two classes (Real and Fake)
plt.xticks(tick_marks, ['Real', 'Fake'])
plt.yticks(tick_marks, ['Real', 'Fake'])

thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, format(cm[i, j], 'd'),
             horizontalalignment="center",
             color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()